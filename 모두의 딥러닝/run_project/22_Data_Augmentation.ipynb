{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.6953 - accuracy: 0.5060 - val_loss: 0.6862 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.6688 - accuracy: 0.6020 - val_loss: 0.6376 - val_accuracy: 0.5200\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.6285 - accuracy: 0.7080 - val_loss: 0.5504 - val_accuracy: 0.8600\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.4687 - accuracy: 0.8040 - val_loss: 0.5725 - val_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.3945 - accuracy: 0.8560 - val_loss: 0.2016 - val_accuracy: 0.9400\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.2876 - accuracy: 0.8860 - val_loss: 0.1595 - val_accuracy: 0.9200\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.2341 - accuracy: 0.9220 - val_loss: 0.1674 - val_accuracy: 0.9200\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.2203 - accuracy: 0.9240 - val_loss: 0.1149 - val_accuracy: 0.9600\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.1817 - accuracy: 0.9360 - val_loss: 0.0855 - val_accuracy: 0.9600\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.1196 - accuracy: 0.9760 - val_loss: 0.0870 - val_accuracy: 0.9600\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 18s 175ms/step - loss: 0.1352 - accuracy: 0.9680 - val_loss: 0.0674 - val_accuracy: 0.9600\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.1392 - accuracy: 0.9580 - val_loss: 0.1332 - val_accuracy: 0.9400\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.0789 - accuracy: 0.9860 - val_loss: 0.0805 - val_accuracy: 0.9600\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.1002 - accuracy: 0.9720 - val_loss: 0.0966 - val_accuracy: 0.9600\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.1284 - accuracy: 0.9660 - val_loss: 0.0580 - val_accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.0917 - accuracy: 0.9660 - val_loss: 0.2726 - val_accuracy: 0.9200\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.1057 - accuracy: 0.9620 - val_loss: 0.0386 - val_accuracy: 0.98001105 - ac\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.0732 - accuracy: 0.9780 - val_loss: 0.0554 - val_accuracy: 0.9600\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.0830 - accuracy: 0.9840 - val_loss: 0.1183 - val_accuracy: 0.9600\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.0931 - accuracy: 0.9620 - val_loss: 0.0318 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  horizontal_flip=True,     #수평 대칭 이미지를 50% 확률로 만들어 추가합니다.\n",
    "                                  width_shift_range=0.1,  #전체 크기의 10% 범위에서 좌우로 이동합니다.\n",
    "                                  height_shift_range=0.1, #마찬가지로 위, 아래로 이동합니다.\n",
    "                                  #rotation_range=5,\n",
    "                                  #shear_range=0.7,\n",
    "                                  #zoom_range=[0.9, 2.2],\n",
    "                                  #vertical_flip=True,\n",
    "                                  fill_mode='nearest') \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "       './train',   #학습셋이 있는 폴더의 위치입니다.\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')\n",
    "\n",
    "#테스트 셋은 이미지 부풀리기 과정을 진행하지 않습니다.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "       './test',   #테스트셋이 있는 폴더의 위치입니다.\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')\n",
    "\n",
    "\n",
    "# 앞서 배운 CNN 모델을 만들어 적용해 보겠습니다.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150,150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#모델을 컴파일 합니다. \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
    "\n",
    "#모델을 실행합니다\n",
    "history = model.fit_generator(\n",
    "       train_generator,\n",
    "       steps_per_epoch=100,\n",
    "       epochs=20,\n",
    "       validation_data=test_generator,\n",
    "       validation_steps=10)\n",
    "\n",
    "#결과를 그래프로 표현하는 부분입니다.\n",
    "acc= history.history['accuracy']\n",
    "val_acc= history.history['val_accuracy']\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))  \n",
    "plt.plot(x_len, acc, marker='.', c=\"red\", label='Trainset_acc')\n",
    "plt.plot(x_len, val_acc, marker='.', c=\"lightcoral\", label='Testset_acc')\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"cornflowerblue\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right') \n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/acc')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
